## 9 Support Vector Machines in R
# chapter1
Visualizing a sugar content dataset
In this exercise, you will create a 1-dimensional scatter plot of 25 soft drink sugar content measurements. The aim is to visualize distinct clusters in the dataset as a first step towards identifying candidate decision boundaries.

The dataset with 25 sugar content measurements is stored in the sugar_content column of the data frame df, which has been preloaded for you.
 # Load ggplot2
> library(ggplot2)
> 
> # Print variable names
> names(df)
[1] "sample."       "sugar_content"
> 
> # Plot sugar content along the x-axis
> plot_df <- ggplot(data = df, aes(x = sugar_content, y =0)) + 
      geom_point() + 
      geom_text(aes(label = sugar_content), size = 2.5, vjust = 2, hjust = 0.5)
> 
> # Display plot
> plot_df
> Find the maximal margin separator
Recall that the dataset we are working with consists of measurements of sugar content of 25 randomly chosen samples of two soft drinks, one regular and the other reduced sugar. In one of our earlier plots, we identified two distinct clusters (classes). A dataset in which the classes do not overlap is called separable, the classes being separated by a decision boundary. The maximal margin separator is the decision boundary that is furthest from both classes. It is located at the mean of the relevant extreme points from each class. In this case the relevant points are the highest valued point in the low sugar content class and the lowest valued point in the high sugar content class. This exercise asks you to find the maximal margin separator for the sugar content dataset.
#The maximal margin separator is at the midpoint of the two extreme points in each cluster.
> mm_separator <- (8.9+ 10)/2
Visualize the maximal margin separator
In this exercise you will add the maximal margin separator to the scatter plot you created in an earlier exercise. The plot has been reproduced on the right.
#create data frame containing the maximum margin separator
> separator <- data.frame(sep = mm_separator)
> 
> #add ggplot layer
> plot_sep <- plot_ + geom_point(data = separator, aes(x=sep,y = 0), color = "blue", size = 4)
> 
> #display plot
> plot_sep
> Generate a 2d uniformly distributed dataset.
The aim of this lesson is to create a dataset that will be used to illustrate the basic principles of support vector machines. In this exercise we will do the first step, which is to create a 2 dimensional uniformly distributed dataset containing 600 datapoints.
 #set seed
> set.seed(42)
> 
> #set number of data points.
> n <- 600
> 
> #Generate data frame with two uniformly distributed predictors lying between 0 and 1.
> df <- data.frame(x1 = runif(n), 
                   x2 = runif(n))
> Create a decision boundary
The dataset you created in the previous exercise is available to you in the dataframe df (recall that it consists of two uniformly distributed variables x1 and x2, lying between 0 and 1). In this exercise you will add a class variable to that dataset. You will do this by creating a variable y whose value is -1 or +1 depending on whether the point (x1, x2) lies below or above the straight line that passes through the origin and has slope 1.4.
#classify data points depending on location
> df$y <- factor(ifelse(df$x2 - 1.4*df$x1 < 0, -1, 1), 
      levels = c(-1, 1))
> Introduce a margin in the dataset
Your final task for Chapter 1 is to create a margin in the dataset that you generated in the previous exercise and then display the margin in a plot. The ggplot2 library has been preloaded for you. Recall that the slope of the linear decision boundary you created in the previous exercise is 1.4.
> #set margin
> delta <- 0.07
> 
> # retain only those points that lie outside the margin
> df1 <- df[abs(1.4*df$x1 - df$x2) > delta, ]
> 
> #build plot
> plot_margins <- ggplot(data = df1, aes(x = x1, y = x2, color = y)) + geom_point() + 
      scale_color_manual(values = c("red", "blue")) + 
      geom_abline(slope =1.4, intercept = 0)+
      geom_abline(slope = 1.4, intercept = delta, linetype = "dashed") +
      geom_abline(slope = 1.4, intercept = -delta, linetype = "dashed")
> 
> #display plot
> plot_margins
> 
## chap-2-Linear Support Vector Machines
Creating training and test datasets
Splitting a dataset into training and test sets is an important step in building and testing a classification model. The training set is used to build the model and the test set to evaluate its predictive accuracy.

In this exercise, you will split the dataset you created in the previous chapter into training and test sets. The dataset has been loaded in the dataframe df and a seed has already been set to ensure reproducibility.
> #split train and test data in an 80/20 proportion
> df[, "train"] <- ifelse(runif(nrow(df))<0.8, 1, 0)
> 
> #assign training rows to data frame trainset
> trainset <- df[df$train == 1, ]
> #assign test rows to data frame testset
> testset <- df[df$train == 0, ]
> 
> #find index of "train" column
> trainColNum <- grep("train", names(trainset))
> 
> #remove "train" column from train and test dataset
> trainset <- trainset[, -trainColNum]
> testset <- testset[, -trainColNum]
> Building a linear SVM classifier
In this exercise, you will use the svm() function from the e1071 library to build a linear SVM classifier using training dataset you created in the previous exercise. The training dataset has been loaded for you in the dataframe trainset
> library(e1071)
> 
> #build svm model, setting required parameters
> svm_model<- svm(y ~ ., 
                  data = trainset, 
                  type = "C-classification", 
                  kernel = "linear", 
                  scale = FALSE)
> Exploring the model and calculating accuracy
In this exercise you will explore the contents of the model and calculate its training and test accuracies. The training and test data are available in the data frames trainset and testset respectively, and the SVM model is stored in the variable svm_model.
> #list components of model
> names(svm_model)
 [1] "call"            "type"            "kernel"          "cost"           
 [5] "degree"          "gamma"           "coef0"           "nu"             
 [9] "epsilon"         "sparse"          "scaled"          "x.scale"        
[13] "y.scale"         "nclasses"        "levels"          "tot.nSV"        
[17] "nSV"             "labels"          "SV"              "index"          
[21] "rho"             "compprob"        "probA"           "probB"          
[25] "sigma"           "coefs"           "na.action"       "fitted"         
[29] "decision.values" "terms"
> #list components of model
> names(svm_model)
 [1] "call"            "type"            "kernel"          "cost"           
 [5] "degree"          "gamma"           "coef0"           "nu"             
 [9] "epsilon"         "sparse"          "scaled"          "x.scale"        
[13] "y.scale"         "nclasses"        "levels"          "tot.nSV"        
[17] "nSV"             "labels"          "SV"              "index"          
[21] "rho"             "compprob"        "probA"           "probB"          
[25] "sigma"           "coefs"           "na.action"       "fitted"         
[29] "decision.values" "terms"
> 
> #list values of the SV, index and rho
> svm_model$SV
              x1          x2
7   0.4577417762 0.476919189
13  0.4749970816 0.486642912
29  0.3795592405 0.313981685
33  0.4317512489 0.520339758
46  0.6756072745 0.772399305
52  0.6932048204 0.838569788
55  0.2163854151 0.082716837
57  0.1974103423 0.095661407
72  0.7439746463 0.912029979
74  0.6262453445 0.765520479
76  0.2165673110 0.202548483
86  0.3556659538 0.298152283
105 0.4640695513 0.535269056
106 0.7793681615 0.941694443
107 0.7335279596 0.892355152
109 0.1701624813 0.050030747
128 0.4140496817 0.380267640
131 0.1364903601 0.011009041
135 0.7690324257 0.951921815
151 0.4427962683 0.532290264
154 0.2524584394 0.281511990
166 0.8205145481 0.962842692
167 0.3070544004 0.226466750
184 0.2697161783 0.288755647
190 0.3110496188 0.298268895
195 0.2050496121 0.182046106
199 0.7853494422 0.870432480
204 0.4037828147 0.476424339
209 0.1709963905 0.164468810
216 0.3864540118 0.370921416
217 0.3324459905 0.382318948
229 0.3921784570 0.343302177
245 0.5648222226 0.618285144
253 0.6753195773 0.773493237
256 0.3169501573 0.333509587
260 0.3597852497 0.345139100
292 0.6568108753 0.815567016
296 0.0755990995 0.007417523
299 0.1079870730 0.022227321
305 0.2401496081 0.151690785
325 0.3626018071 0.369346223
341 0.6399842701 0.695480783
365 0.5195604505 0.627322678
383 0.6494539515 0.833293378
391 0.4243346907 0.470753220
400 0.3458497624 0.413091426
419 0.2065700251 0.089081859
429 0.7148487861 0.902375512
434 0.8058112133 0.937903824
438 0.4587231132 0.446819442
10  0.4622928225 0.839631285
19  0.4469696281 0.721333573
26  0.0073341469 0.108096598
44  0.2610879638 0.472588875
51  0.2712866147 0.560707851
65  0.3052183695 0.548420829
66  0.0002388966 0.122946701
75  0.2171576982 0.505044580
77  0.3889450287 0.717138722
84  0.4527315726 0.737772155
93  0.2335235255 0.439058027
96  0.6034740848 0.958318281
97  0.6315072989 0.970767964
112 0.1490720524 0.377477208
118 0.0290858189 0.148069276
130 0.4274944656 0.725024226
133 0.5923042425 0.900228734
141 0.1333296183 0.390023998
146 0.0531294835 0.276241161
150 0.5171110556 0.899924811
155 0.2596899802 0.503687580
157 0.4513108502 0.743930877
159 0.5746373343 0.930141046
169 0.0483467767 0.218475638
172 0.1590223818 0.402696270
176 0.0865806018 0.263718613
180 0.1495789951 0.351843507
181 0.4992728804 0.812805236
188 0.5397982858 0.932383237
202 0.3367135401 0.672058288
211 0.0186874117 0.097642665
215 0.3152607968 0.625878707
230 0.3199476011 0.541676977
241 0.4303332213 0.792282316
263 0.3733412449 0.718439230
273 0.5825784358 0.900965292
301 0.0842775232 0.235715229
317 0.5141573721 0.908452330
340 0.1147626776 0.363946523
344 0.3479114065 0.564496977
348 0.5964720468 0.913432184
354 0.2485451805 0.533491509
368 0.1465723943 0.391752972
382 0.1270027745 0.348539336
387 0.2665205784 0.458110426
407 0.2770604359 0.510976796
423 0.5705413527 0.994652604
424 0.2458533479 0.494881822
427 0.4806177358 0.786027395
430 0.3165616125 0.563688410
> svm_model$index
  [1]   7  13  29  33  46  52  55  57  72  74  76  86 105 106 107 109 128 131
 [19] 135 151 154 166 167 184 190 195 199 204 209 216 217 229 245 253 256 260
 [37] 292 296 299 305 325 341 365 383 391 400 419 429 434 438  10  19  26  44
 [55]  51  65  66  75  77  84  93  96  97 112 118 130 133 141 146 150 155 157
 [73] 159 169 172 176 180 181 188 202 211 215 230 241 263 273 301 317 340 344
 [91] 348 354 368 382 387 407 423 424 427 430
> svm_model$rho
[1] 0.02610377
> #list components of model
> names(svm_model)
 [1] "call"            "type"            "kernel"          "cost"           
 [5] "degree"          "gamma"           "coef0"           "nu"             
 [9] "epsilon"         "sparse"          "scaled"          "x.scale"        
[13] "y.scale"         "nclasses"        "levels"          "tot.nSV"        
[17] "nSV"             "labels"          "SV"              "index"          
[21] "rho"             "compprob"        "probA"           "probB"          
[25] "sigma"           "coefs"           "na.action"       "fitted"         
[29] "decision.values" "terms"
> 
> #list values of the SV, index and rho
> svm_model$SV
              x1          x2
7   0.4577417762 0.476919189
13  0.4749970816 0.486642912
29  0.3795592405 0.313981685
33  0.4317512489 0.520339758
46  0.6756072745 0.772399305
52  0.6932048204 0.838569788
55  0.2163854151 0.082716837
57  0.1974103423 0.095661407
72  0.7439746463 0.912029979
74  0.6262453445 0.765520479
76  0.2165673110 0.202548483
86  0.3556659538 0.298152283
105 0.4640695513 0.535269056
106 0.7793681615 0.941694443
107 0.7335279596 0.892355152
109 0.1701624813 0.050030747
128 0.4140496817 0.380267640
131 0.1364903601 0.011009041
135 0.7690324257 0.951921815
151 0.4427962683 0.532290264
154 0.2524584394 0.281511990
166 0.8205145481 0.962842692
167 0.3070544004 0.226466750
184 0.2697161783 0.288755647
190 0.3110496188 0.298268895
195 0.2050496121 0.182046106
199 0.7853494422 0.870432480
204 0.4037828147 0.476424339
209 0.1709963905 0.164468810
216 0.3864540118 0.370921416
217 0.3324459905 0.382318948
229 0.3921784570 0.343302177
245 0.5648222226 0.618285144
253 0.6753195773 0.773493237
256 0.3169501573 0.333509587
260 0.3597852497 0.345139100
292 0.6568108753 0.815567016
296 0.0755990995 0.007417523
299 0.1079870730 0.022227321
305 0.2401496081 0.151690785
325 0.3626018071 0.369346223
341 0.6399842701 0.695480783
365 0.5195604505 0.627322678
383 0.6494539515 0.833293378
391 0.4243346907 0.470753220
400 0.3458497624 0.413091426
419 0.2065700251 0.089081859
429 0.7148487861 0.902375512
434 0.8058112133 0.937903824
438 0.4587231132 0.446819442
10  0.4622928225 0.839631285
19  0.4469696281 0.721333573
26  0.0073341469 0.108096598
44  0.2610879638 0.472588875
51  0.2712866147 0.560707851
65  0.3052183695 0.548420829
66  0.0002388966 0.122946701
75  0.2171576982 0.505044580
77  0.3889450287 0.717138722
84  0.4527315726 0.737772155
93  0.2335235255 0.439058027
96  0.6034740848 0.958318281
97  0.6315072989 0.970767964
112 0.1490720524 0.377477208
118 0.0290858189 0.148069276
130 0.4274944656 0.725024226
133 0.5923042425 0.900228734
141 0.1333296183 0.390023998
146 0.0531294835 0.276241161
150 0.5171110556 0.899924811
155 0.2596899802 0.503687580
157 0.4513108502 0.743930877
159 0.5746373343 0.930141046
169 0.0483467767 0.218475638
172 0.1590223818 0.402696270
176 0.0865806018 0.263718613
180 0.1495789951 0.351843507
181 0.4992728804 0.812805236
188 0.5397982858 0.932383237
202 0.3367135401 0.672058288
211 0.0186874117 0.097642665
215 0.3152607968 0.625878707
230 0.3199476011 0.541676977
241 0.4303332213 0.792282316
263 0.3733412449 0.718439230
273 0.5825784358 0.900965292
301 0.0842775232 0.235715229
317 0.5141573721 0.908452330
340 0.1147626776 0.363946523
344 0.3479114065 0.564496977
348 0.5964720468 0.913432184
354 0.2485451805 0.533491509
368 0.1465723943 0.391752972
382 0.1270027745 0.348539336
387 0.2665205784 0.458110426
407 0.2770604359 0.510976796
423 0.5705413527 0.994652604
424 0.2458533479 0.494881822
427 0.4806177358 0.786027395
430 0.3165616125 0.563688410
> svm_model$index
  [1]   7  13  29  33  46  52  55  57  72  74  76  86 105 106 107 109 128 131
 [19] 135 151 154 166 167 184 190 195 199 204 209 216 217 229 245 253 256 260
 [37] 292 296 299 305 325 341 365 383 391 400 419 429 434 438  10  19  26  44
 [55]  51  65  66  75  77  84  93  96  97 112 118 130 133 141 146 150 155 157
 [73] 159 169 172 176 180 181 188 202 211 215 230 241 263 273 301 317 340 344
 [91] 348 354 368 382 387 407 423 424 427 430
> svm_model$rho
[1] 0.02610377
> 
> #compute training accuracy
> pred_train <- predict(svm_model, trainset)
> mean(pred_train == trainset$y)
[1] 1
> #list components of model
> names(svm_model)
 [1] "call"            "type"            "kernel"          "cost"           
 [5] "degree"          "gamma"           "coef0"           "nu"             
 [9] "epsilon"         "sparse"          "scaled"          "x.scale"        
[13] "y.scale"         "nclasses"        "levels"          "tot.nSV"        
[17] "nSV"             "labels"          "SV"              "index"          
[21] "rho"             "compprob"        "probA"           "probB"          
[25] "sigma"           "coefs"           "na.action"       "fitted"         
[29] "decision.values" "terms"
> 
> #list values of the SV, index and rho
> svm_model$SV
              x1          x2
7   0.4577417762 0.476919189
13  0.4749970816 0.486642912
29  0.3795592405 0.313981685
33  0.4317512489 0.520339758
46  0.6756072745 0.772399305
52  0.6932048204 0.838569788
55  0.2163854151 0.082716837
57  0.1974103423 0.095661407
72  0.7439746463 0.912029979
74  0.6262453445 0.765520479
76  0.2165673110 0.202548483
86  0.3556659538 0.298152283
105 0.4640695513 0.535269056
106 0.7793681615 0.941694443
107 0.7335279596 0.892355152
109 0.1701624813 0.050030747
128 0.4140496817 0.380267640
131 0.1364903601 0.011009041
135 0.7690324257 0.951921815
151 0.4427962683 0.532290264
154 0.2524584394 0.281511990
166 0.8205145481 0.962842692
167 0.3070544004 0.226466750
184 0.2697161783 0.288755647
190 0.3110496188 0.298268895
195 0.2050496121 0.182046106
199 0.7853494422 0.870432480
204 0.4037828147 0.476424339
209 0.1709963905 0.164468810
216 0.3864540118 0.370921416
217 0.3324459905 0.382318948
229 0.3921784570 0.343302177
245 0.5648222226 0.618285144
253 0.6753195773 0.773493237
256 0.3169501573 0.333509587
260 0.3597852497 0.345139100
292 0.6568108753 0.815567016
296 0.0755990995 0.007417523
299 0.1079870730 0.022227321
305 0.2401496081 0.151690785
325 0.3626018071 0.369346223
341 0.6399842701 0.695480783
365 0.5195604505 0.627322678
383 0.6494539515 0.833293378
391 0.4243346907 0.470753220
400 0.3458497624 0.413091426
419 0.2065700251 0.089081859
429 0.7148487861 0.902375512
434 0.8058112133 0.937903824
438 0.4587231132 0.446819442
10  0.4622928225 0.839631285
19  0.4469696281 0.721333573
26  0.0073341469 0.108096598
44  0.2610879638 0.472588875
51  0.2712866147 0.560707851
65  0.3052183695 0.548420829
66  0.0002388966 0.122946701
75  0.2171576982 0.505044580
77  0.3889450287 0.717138722
84  0.4527315726 0.737772155
93  0.2335235255 0.439058027
96  0.6034740848 0.958318281
97  0.6315072989 0.970767964
112 0.1490720524 0.377477208
118 0.0290858189 0.148069276
130 0.4274944656 0.725024226
133 0.5923042425 0.900228734
141 0.1333296183 0.390023998
146 0.0531294835 0.276241161
150 0.5171110556 0.899924811
155 0.2596899802 0.503687580
157 0.4513108502 0.743930877
159 0.5746373343 0.930141046
169 0.0483467767 0.218475638
172 0.1590223818 0.402696270
176 0.0865806018 0.263718613
180 0.1495789951 0.351843507
181 0.4992728804 0.812805236
188 0.5397982858 0.932383237
202 0.3367135401 0.672058288
211 0.0186874117 0.097642665
215 0.3152607968 0.625878707
230 0.3199476011 0.541676977
241 0.4303332213 0.792282316
263 0.3733412449 0.718439230
273 0.5825784358 0.900965292
301 0.0842775232 0.235715229
317 0.5141573721 0.908452330
340 0.1147626776 0.363946523
344 0.3479114065 0.564496977
348 0.5964720468 0.913432184
354 0.2485451805 0.533491509
368 0.1465723943 0.391752972
382 0.1270027745 0.348539336
387 0.2665205784 0.458110426
407 0.2770604359 0.510976796
423 0.5705413527 0.994652604
424 0.2458533479 0.494881822
427 0.4806177358 0.786027395
430 0.3165616125 0.563688410
> svm_model$index
  [1]   7  13  29  33  46  52  55  57  72  74  76  86 105 106 107 109 128 131
 [19] 135 151 154 166 167 184 190 195 199 204 209 216 217 229 245 253 256 260
 [37] 292 296 299 305 325 341 365 383 391 400 419 429 434 438  10  19  26  44
 [55]  51  65  66  75  77  84  93  96  97 112 118 130 133 141 146 150 155 157
 [73] 159 169 172 176 180 181 188 202 211 215 230 241 263 273 301 317 340 344
 [91] 348 354 368 382 387 407 423 424 427 430
> svm_model$rho
[1] 0.02610377
> 
> #compute training accuracy
> pred_train <- predict(svm_model, trainset)
> mean(pred_train == trainset$y)
[1] 1
> 
> #compute test accuracy
> pred_test <- predict(svm_model, testset)
> mean(pred_test == testset$y)
[1] 1
> Visualizing support vectors using ggplot
In this exercise you will plot the training dataset you used to build a linear SVM and mark out the support vectors. The training dataset has been preloaded for you in the dataframe trainset and the SVM model is stored in the variable svm_model.
> #load ggplot
> library(ggplot2)
> 
> #build scatter plot of training dataset
> scatter_plot <- ggplot(data = trainset, aes(x = x1, y = x2, color = y)) + 
      geom_point() + 
      scale_color_manual(values = c("red", "blue"))
> 
> #add plot layer marking out the support vectors
> layered_plot <- 
      scatter_plot + geom_point(data = trainset[svm_model$index, ], aes(x = x1, y = x2), color = "purple", size = 4, alpha = 0.5)
> 
> #display plot
> layered_plot
> Visualizing decision & margin bounds using `ggplot2`
In this exercise, you will add the decision and margin boundaries to the support vector scatter plot created in the previous exercise. The SVM model is available in the variable svm_model and the weight vector has been precalculated for you and is available in the variable w. The ggplot2 library has also been preloaded.
> #calculate slope and intercept of decision boundary from weight vector and svm model
> slope_1 <- -w[1]/w[2]
> intercept_1 <-  svm_model$rho/w[2]
> 
> #build scatter plot of training dataset
> scatter_plot <- ggplot(data = trainset, aes(x = x1, y = x2, color = y)) + 
      geom_point() + scale_color_manual(values = c("red", "blue"))
> #add decision boundary
> plot_decision <- scatter_plot + geom_abline(slope = slope_1, intercept = intercept_1)
> #add margin boundaries
> plot_margins <- plot_decision + 
   geom_abline(slope = slope_1, intercept = intercept_1 - 1/w[2], linetype = "dashed")+
   geom_abline(slope = slope_1, intercept = intercept_1 + 1/w[2], linetype = "dashed")
> #display plot
> plot_margins
> Visualizing decision & margin bounds using `plot()`
In this exercise, you will rebuild the SVM model (as a refresher) and use the built in SVM plot() function to visualize the decision regions and support vectors. The training data is available in the dataframe trainset
> #load required library
> library(e1071)
> 
> #build svm model
> svm_model<- 
      svm(y ~ ., data = trainset, type = "C-classification", 
          kernel = "linear", scale = FALSE)
> 
> #plot decision boundaries and support vectors for the training data
> plot(x = svm_model, data = trainset)
> Tuning a linear SVM
In this exercise you will study the influence of varying cost on the number of support vectors for linear SVMs. To do this, you will build two SVMs, one with cost = 1 and the other with cost = 100 and find the number of support vectors. A model training dataset is available in the dataframe trainset.
#build svm model, cost = 1
> svm_model_1 <- svm(y ~ .,
                     data = trainset,
                     type = "C-classification",
                     cost = 1,
                     kernel = "linear",
                     scale = FALSE)
> 
> #print model details
> svm_model_1

Call:
svm(formula = y ~ ., data = trainset, type = "C-classification", 
    cost = 1, kernel = "linear", scale = FALSE)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  linear 
       cost:  1 
      gamma:  0.5 

Number of Support Vectors:  100
> #build svm model, cost = 100
> svm_model_100 <- svm(y ~ .,
                     data = trainset,
                     type = "C-classification",
                     cost = 100,
                     kernel = "linear",
                     scale = FALSE)
> 
> #print model details
> svm_model_100

Call:
svm(formula = y ~ ., data = trainset, type = "C-classification", 
    cost = 100, kernel = "linear", scale = FALSE)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  linear 
       cost:  100 
      gamma:  0.5 

Number of Support Vectors:  7
> isualizing decision boundaries and margins
In the previous exercise you built two linear classifiers for a linearly separable dataset, one with cost = 1 and the other cost = 100. In this exercise you will visualize the margins for the two classifiers on a single plot. The following objects are available for use:

The training dataset: trainset.
The cost = 1 and cost = 100 classifiers in svm_model_1 and svm_model_100, respectively.
The slope and intercept for the cost = 1 classifier is stored in slope_1 and intercept_1.
The slope and intercept for the cost = 100 classifier is stored in slope_100 and intercept_100.
Weight vectors for the two costs are stored in w_1 and w_100, respectively
A basic scatter plot of the training data is stored in train_plot
The ggplot2 library has been preloaded.
#add decision boundary and margins for cost = 1 to training data scatter plot
train_plot_with_margins <- train_plot + 
    geom_abline(slope = slope_1, intercept = intercept_1) +
    geom_abline(slope = slope_100, intercept = intercept_100-1/w_1[2], linetype = "dashed")+
    geom_abline(slope = slope_1, intercept = intercept_1+1/w_1[2], linetype = "dashed")

#display plot
train_plot_with_margins
#add decision boundary and margins for cost = 100 to training data scatter plot
train_plot_with_margins <- train_plot_100 + 
    geom_abline(slope = slope_1, intercept = intercept_1, color = "goldenrod") +
    geom_abline(slope = slope_100, intercept = intercept_100-1/w_100[2], linetype = "dashed", color = "goldenrod")+
    geom_abline(slope = slope_100, intercept = intercept_1+1/w_100[2], linetype = "dashed", color = "goldenrod")

#display plot 
train_plot_with_margins 
A multiclass classification problem
In this exercise, you will use the svm() function from the e1071 library to build a linear multiclass SVM classifier for a dataset that is known to be perfectly linearly separable. Calculate the training and test accuracies, and plot the model using the training data. The training and test datasets are available in the dataframes trainset and testset. Use the default setting for the cost parameter.
#load library and build svm model
> library(e1071)
> svm_model<- 
      svm(y ~ ., data =trainset, type = "C-classification", 
          kernel = "linear", scale = FALSE)
> > #load library and build svm model
> library(e1071)
> svm_model<- 
      svm(y ~ ., data = trainset, type = "C-classification", 
          kernel = "linear", scale = FALSE)
> 
> #compute training accuracy
> pred_train <- predict(svm_model, trainset)
> mean(pred_train == trainset$y)
[1] 0.9875969
> #compute test accuracy
> pred_test <- predict(svm_model, testset)
> mean(pred_test == testset$y)
[1] 0.9806452
 #plot
> plot(svm_model, trainset)
Iris redux - a more robust accuracy.
In this exercise, you will build linear SVMs for 100 distinct training/test partitions of the iris dataset. You will then evaluate the performance of your model by calculating the mean accuracy and standard deviation. This procedure, which is quite general, will give you a far more robust measure of model performance than the ones obtained from a single partition.
> for (i in 1:100){
    	#assign 80% of the data to the training set
      iris[, "train"] <- ifelse(runif(nrow(iris)) < 0.8, 1, 0)
      trainColNum <- grep("train", names(iris))
      trainset <- iris[iris$train == 1, -trainColNum]
      testset <- iris[iris$train == 0, -trainColNum]
    	#build model using training data
      svm_model <- svm(Species~ ., data = trainset, 
                       type = "C-classification", kernel = "linear")
    	#calculate accuracy on test data
      pred_test <- predict(svm_model, testset)
      accuracy[i] <- mean(pred_test == testset$Species)
  }
> mean(accuracy)
[1] 0.9620757
> sd(accuracy)
[1] 0.03443983
> 
#chap-3-Generating a radially separable dataset
Generating a 2d radially separable dataset
In this exercise you will create a 2d radially separable dataset containing 400 uniformly distributed data points.
> #set number of variables and seed
> n <- 400
> set.seed(1)
> 
> #Generate data frame with two uniformly distributed predictors, x1 and x2
> df <- data.frame(x1 = runif(n, min = -1, max = 1), 
                   x2 = runif(n, min = -1, max = 1))
> 
> #We want a circular boundary. Set boundary radius
> radius <- 0.8
> radius_squared <- radius^2
> 
> #create dependent categorical variable, y, with value -1 or 1 depending on whether point lies
> #within or outside the circle.
> df$y <- factor(ifelse(df$x1^2+ df$x2^2< radius_squared, -1, 1), levels = c(-1, 1))
> Visualizing the dataset
In this exercise you will use ggplot() to visualize the dataset you created in the previous exercise. The dataset is available in the dataframe df. Use color to distinguish between the two classes.
> #load ggplot
> library(ggplot2)
> 
> #build scatter plot, distinguish class by color
> scatter_plot <- ggplot(data = df, aes(x = x1, y = x2, color = y)) + 
     geom_point() +
      scale_color_manual(values = c("red", "blue"))
> 
> #display plot
> scatter_plot
> Linear SVM for a radially separable dataset
In this exercise you will build two linear SVMs, one for cost = 1 (default) and the other for cost = 100, for the radially separable dataset you created in the first lesson of this chapter. You will also calculate the training and test accuracies for both costs. The e1071 library has been loaded, and test and training datasets have been created for you and are available in the data frames trainset and testset.
> #default cost mode;
> svm_model_1 <- svm(y ~ ., data = trainset, type = "C-classification", cost = 1, kernel = "linear")
> 
> #training accuracy
> pred_train <- predict(svm_model_1, trainset)
> mean(pred_train == trainset$y)
[1] 0.5414013
> 
> #test accuracy
> pred_test <- predict(svm_model_1, testset)
> mean(pred_test == testset$y)
[1] 0.5930233
> #cost = 100 model
> svm_model_2 <- svm(y ~ ., data = trainset, type = "C-classification", cost = 100, kernel = "linear")
> 
> #accuracy
> pred_train <- predict(svm_model_2, trainset)
> mean(pred_train == trainset$y)
[1] 0.5414013
> pred_test <- predict(svm_model_2, testset)
> mean(pred_test == testset$y)
[1] 0.5930233
> Average accuracy for linear SVM
In this exercise you will calculate the average accuracy for a default cost linear SVM using 100 different training/test partitions of the dataset you generated in the first lesson of this chapter. The e1071 library has been preloaded and the dataset is available in the dataframe df. Use random 80/20 splits of the data in df when creating training and test datasets for each iteration.
> # Print average accuracy and standard deviation
> accuracy <- rep(NA, 100)
> set.seed(2)
> 
> # Calculate accuracies for 100 training/test partitions
> for (i in 1:100){
      df[, "train"] <- ifelse(runif(nrow(df)) < 0.8, 1, 0)
      trainset <- df[df$train == 1, ]
      testset <- df[df$train == 0, ]
      trainColNum <- grep("train", names(trainset))
      trainset <- trainset[, -trainColNum]
      testset <- testset[, -trainColNum]
      svm_model <- svm(y ~ ., data = trainset, type = "C-classification", kernel = "linear")
      pred_test <- predict(svm_model, testset)
      accuracy[i] <- mean(pred_test == testset$y)
  }
> 
> # Print average accuracy and standard deviation
> mean(accuracy)
[1] 0.5554571
> sd(accuracy)
[1] 0.04243524
> Visualizing transformed radially separable data
In this exercise you will transform the radially separable dataset you created earlier in this chapter and visualize it in the x1^2-x2^2 plane. As a reminder, the separation boundary for the data is the circle x1^2 + x2^2 = 0.64(radius = 0.8 units). The dataset has been loaded for you in the dataframe df.
> #transform data
> df1 <- data.frame(x1sq = df$x1^2, x2sq = df$x2^2, y = df$y)
> 
> #plot data points in the transformed space
> plot_transformed <- ggplot(data = df1, aes(x = x1sq, y = x2sq , color = y)) + 
      geom_point()+ guides(color = FALSE) + 
      scale_color_manual(values = c("red", "blue"))
> 
> #add decision boundary and visualize
> plot_decision <- plot_transformed + geom_abline(slope = -1, intercept = 0.64)
> plot_decision
> SVM with polynomial kernel
In this exercise you will build a SVM with a quadratic kernel (polynomial of degree 2) for the radially separable dataset you created earlier in this chapter. You will then calculate the training and test accuracies and create a plot of the model using the built in plot() function. The training and test datasets are available in the dataframes trainset and testset, and the e1071 library has been preloaded.
> svm_model<- 
      svm(y ~ ., data = trainset, type = "C-classification", 
          kernel = "polynomial", degree = 2)
> 
> #measure training and test accuracy
> pred_train <- predict(svm_model, trainset)
> mean(pred_train == trainset$y)
[1] 0.9745223
> pred_test <- predict(svm_model, testset)
> mean(pred_test == testset$y)
[1] 0.9651163
> 
> #plot
> plot(svm_model, trainset)
> Using `tune.svm()`
This exercise will give you hands-on practice with using the tune.svm() function. You will use it to obtain the optimal values for the cost, gamma, and coef0 parameters for an SVM model based on the radially separable dataset you created earlier in this chapter. The training data is available in the dataframe trainset, the test data in testset, and the e1071 library has been preloaded for you. Remember that the class variable y is stored in the third column of the trainset and testset.

Also recall that in the video, Kailash used cost=10^(1:3) to get a range of the cost parameter from 10=10^1 to 1000=10^3 in multiples of 10.
> #tune model
> tune_out <- 
      tune.svm(x = trainset[, -3], y = trainset[, 3], 
               type = "C-classification", 
               kernel = "polynomial", degree = 2, cost = 10^(-1:2), 
               gamma = c(0.1, 1, 10), coef0 = c(0.1, 1, 10))
> 
> #list optimal values
> tune_out$best.parameters$degree
[1] 2
> tune_out$best.parameters$gamma
[1] 10
> tune_out$best.parameters$coef0
[1] 0.1
> Building and visualizing the tuned model
In the final exercise of this chapter, you will build a polynomial SVM using the optimal values of the parameters that you obtained from tune.svm() in the previous exercise. You will then calculate the training and test accuracies and visualize the model using svm.plot(). The e1071 library has been preloaded and the test and training datasets are available in the dataframes trainset and testset. The output of tune.svm() is available in the variable tune_out.
> #Build tuned model
> svm_model <- svm(y~ ., data = trainset, type = "C-classification", 
                   kernel = "polynomial", degree = 2, 
                   cost = tune_out$best.parameters$cost, 
                   gamma = tune_out$best.parameters$gamma, 
                   coef0 = tune_out$best.parameters$coef0)
> 
> #Calculate training and test accuracies
> pred_train <- predict(svm_model, trainset)
> mean(pred_train == trainset$y)
[1] 1
> pred_test <- predict(svm_model, testset)
> mean(pred_test == testset$y)
[1] 0.9883721
> 
> #plot model
> plot(svm_model, trainset)
# chap-4-Generating a complex dataset
Generating a complex dataset - part 1
In this exercise you will create a dataset that has two attributes x1 and x2, with x1 normally distributed (mean = -0.5, sd = 1) and x2 uniformly distributed in (-1, 1).
> #number of data points
> n <- 1000
> 
> #set seed
> set.seed(1)
> 
> #create dataframe
> df <- data.frame(x1 = rnorm(n, mean = -0.5, sd = 1), 
                   x2 = runif(n, min = -1, max = 1))
> Generating a complex dataset - part 2
In this exercise, you will create a decision boundary for the dataset you created in the previous exercise. The boundary consists of two circles of radius 0.8 units with centers at x1 = -0.8, x2 = 0) and (x1 = 0.8, x2 = 0) that just touch each other at the origin. Define a binary classification variable y such that points that lie within either of the circles have y = -1 and those that lie outside both circle have y = 1.

The dataset created in the previous exercise is available in the dataframe df.
> #set radius and centers
> radius <- 0.8
> center_1 <- c(x1 = -0.8, x2 = 0)
> center_2 <- c(x1 = 0.8, x2 = 0)
> radius_squared <- radius^2
> 
> #create binary classification variable
> df$y <- factor(ifelse((df$x1-center_1[1])^2 + (df$x2-center_1[2])^2 < radius_squared|
                        (df$x1-center_2[1])^2 + (df$x2-center_2[2])^2 < radius_squared, -1, 1),
                        levels = c(-1, 1))
> Visualizing the dataset
In this exercise you will use ggplot() to visualise the complex dataset you created in the previous exercises. The dataset is available in the dataframe df. You are not required to visualize the decision boundary.

Here you will use coord_equal() to give the x and y axes the same physical representation on the plot, making the circles appear as circles rather than ellipses
> # Load ggplot2
> library(ggplot2)
> 
> # Plot x2 vs. x1, colored by y
> scatter_plot<- ggplot(data = df, aes(x = x1, y = x2, color = y)) + 
      # Add a point layer
      geom_point() + 
      scale_color_manual(values = c("red", "blue")) +
      # Specify equal coordinates
      coord_equal()
> 
> scatter_plot
> Linear SVM for complex dataset
In this exercise you will build a default cost linear SVM for the complex dataset you created in the first lesson of this chapter. You will also calculate the training and test accuracies and plot the classification boundary against the test dataset. The e1071 library has been loaded, and test and training datasets have been created for you and are available in the data frames trainset and testset.
> #build model
> svm_model<- 
      svm(y ~ ., data = trainset, type = "C-classification", 
          kernel = "linear")
> 
> #accuracy
> pred_train <- predict(svm_model, trainset)
> mean(pred_train == trainset$y)
[1] 0.5897756
> pred_test <- predict(svm_model, testset)
> mean(pred_test == testset$y)
[1] 0.5959596
> 
> #plot model against testset
> plot(svm_model,testset)
Quadratic SVM for complex dataset
In this exercise you will build a default quadratic (polynomial, degree = 2) linear SVM for the complex dataset you created in the first lesson of this chapter. You will also calculate the training and test accuracies plot the classification boundary against the training dataset. The e1071 library has been loaded, and test and training datasets have been created for you and are available in the data frames trainset and testset.
> #build model
> svm_model<- 
      svm(y ~ ., data = trainset, type = "C-classification", 
          kernel = "polynomial", degree = 2)
> 
> #accuracy
> pred_train <- predict(svm_model, trainset)
> mean(pred_train == trainset$y)
[1] 0.8067332
> pred_test <- predict(svm_model, testset)
> mean(pred_test == testset$y)
[1] 0.7979798
> 
> #plot model
> plot(svm_model, trainset)
> Polynomial SVM on a complex dataset
Calculate the average accuracy for a degree 2 polynomial kernel SVM using 100 different training/test partitions of the complex dataset you generated in the first lesson of this chapter. Use default settings for the parameters. The e1071 library has been preloaded and the dataset is available in the dataframe df. Use random 80/20 splits of the data in df when creating training and test datasets for each iteration.
> #create vector to store accuracies and set random number seed
> accuracy <- rep(NA, 100)
> set.seed(2)
> 
> #calculate accuracies for 100 training/test partitions
> for (i in 1:100){
      df[, "train"] <- ifelse(runif(nrow(df))<0.8, 1, 0)
      trainset <- df[df$train == 1, ]
      testset <- df[df$train == 0, ]
      trainColNum <- grep("train", names(trainset))
      trainset <- trainset[, -trainColNum]
      testset <- testset[, -trainColNum]
      svm_model<- svm(y ~ ., data = trainset, type = "C-classification", kernel = "polynomial", degree = 2)
      pred_test <- predict(svm_model, testset)
      accuracy[i] <- mean(pred_test == testset$y)
  }
> 
> #print average accuracy and standard deviation
> mean(accuracy)
[1] 0.804765
> sd(accuracy)
[1] 0.02398396
> RBF SVM on a complex dataset
Calculate the average accuracy for a RBF kernel SVM using 100 different training/test partitions of the complex dataset you generated in the first lesson of this chapter. Use default settings for the parameters. The e1071 library has been preloaded and the dataset is available in the dataframe df. Use random 80/20 splits of the data in df when creating training and test datasets for each iteration.
> #create vector to store accuracies and set random number seed
> accuracy <- rep(NA, 100)
> set.seed(2)
> 
> #calculate accuracies for 100 training/test partitions
> for (i in 1:100){
      df[, "train"] <- ifelse(runif(nrow(df))<0.8, 1, 0)
      trainset <- df[df$train == 1, ]
      testset <- df[df$train == 0, ]
      trainColNum <- grep("train", names(trainset))
      trainset <- trainset[, -trainColNum]
      testset <- testset[, -trainColNum]
      svm_model<- svm(y ~ ., data = trainset, type = "C-classification", kernel = "radial")
      pred_test <- predict(svm_model, testset)
      accuracy[i] <- mean(pred_test == testset$y)
  }
> 
> #print average accuracy and standard deviation
> mean(accuracy)
[1] 0.9034203
> sd(accuracy)
[1] 0.01786378
> Tuning an RBF kernel SVM
In this exercise you will build a tuned RBF kernel SVM for a the given training dataset (available in dataframe trainset) and calculate the accuracy on the test dataset (available in dataframe testset). You will then plot the tuned decision boundary against the test dataset.
> #tune model
> tune_out <- tune.svm(x = trainset[, -3], y = trainset[, 3], 
                       gamma = 5*10^(-2:2), 
                       cost = c(0.01, 0.1, 1, 10, 100), 
                       type = "C-classification", kernel = "radial")
> 
> #build tuned model
> svm_model <- svm(y~ ., data = trainset, type = "C-classification", kernel = "radial", 
                   cost = tune_out$best.parameters$cost, 
                   gamma = tune_out$best.parameters$gamma)
> 
> #calculate test accuracy
> pred_test <- predict(svm_model, testset)
> mean(pred_test == testset$y)
[1] 0.959596
> 
> #Plot decision boundary against test data
> plot(svm_model, testset)
> 
